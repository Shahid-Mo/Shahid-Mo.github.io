<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Quantization in LLMS Part 2: GPTQ (A Mathematical View) | TensorTunes</title>
<meta name="keywords" content="">
<meta name="description" content="Introduction
Quantization is a crucial technique in deep learning that reduces the memory footprint and computational requirements of neural networks by representing weights and activations with lower-precision numerical formats. This is particularly important when deploying large models on devices with limited resources. However, quantizing a neural network without significantly degrading its performance is challenging.
The GPTQ (Gradient Post-Training Quantization) algorithm is a method designed to efficiently quantize large-scale neural networks, such as those used in natural language processing, while maintaining high accuracy.">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/gptq/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/gptq/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="TensorTunes (Alt + H)">TensorTunes</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Quantization in LLMS Part 2: GPTQ (A Mathematical View)
    </h1>
    <div class="post-meta"><span title='2024-08-01 09:51:17 -0400 EDT'>August 1, 2024</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul>
                <li>
                    <a href="#1-problem-statement" aria-label="1. Problem Statement">1. Problem Statement</a></li></ul>
                    
                <li>
                    <a href="#a-quick-refresher-on-constrained-optimaizaiton" aria-label="A Quick Refresher on Constrained Optimaizaiton">A Quick Refresher on Constrained Optimaizaiton</a><ul>
                        
                <li>
                    <a href="#problem-setup" aria-label="Problem Setup:">Problem Setup:</a></li>
                <li>
                    <a href="#lagrange-multipliers" aria-label="Lagrange Multipliers:">Lagrange Multipliers:</a></li>
                <li>
                    <a href="#why-does-this-work-super-optional-read-if-intrested" aria-label="Why Does This Work? (Super Optional: Read if Intrested&hellip;.)">Why Does This Work? (Super Optional: Read if Intrested&hellip;.)</a><ul>
                        
                <li>
                    <a href="#why-are-the-gradients-aligned" aria-label="Why Are the Gradients Aligned?">Why Are the Gradients Aligned?</a></li>
                <li>
                    <a href="#1-the-gradient-and-direction-of-steepest-ascent" aria-label="1. The Gradient and Direction of Steepest Ascent">1. The Gradient and Direction of Steepest Ascent</a></li>
                <li>
                    <a href="#2-feasible-directions-and-tangent-space" aria-label="2. Feasible Directions and Tangent Space">2. Feasible Directions and Tangent Space</a></li>
                <li>
                    <a href="#3-optimality-condition-under-constraint" aria-label="3. Optimality Condition Under Constraint">3. Optimality Condition Under Constraint</a></li>
                <li>
                    <a href="#4-gradients-must-be-parallel" aria-label="4. Gradients Must Be Parallel">4. Gradients Must Be Parallel</a></li></ul>
                </li>
                <li>
                    <a href="#steps-to-solve" aria-label="Steps to Solve:">Steps to Solve:</a></li>
                <li>
                    <a href="#a-quick-review-of-taylor-series" aria-label="A quick review of Taylor Series">A quick review of Taylor Series</a></li></ul>
                </li>
                <li>
                    <a href="#obs-optimnal-brain-surgery" aria-label="OBS (Optimnal Brain Surgery)">OBS (Optimnal Brain Surgery)</a><ul>
                        
                <li>
                    <a href="#overview" aria-label="Overview">Overview</a></li>
                <li>
                    <a href="#problem-context" aria-label="Problem Context">Problem Context</a></li>
                <li>
                    <a href="#optimization-problem" aria-label="Optimization Problem">Optimization Problem</a></li>
                <li>
                    <a href="#mathematical-formulation" aria-label="Mathematical Formulation">Mathematical Formulation</a></li>
                <li>
                    <a href="#setting-up-the-optimization-problem" aria-label="Setting up the Optimization Problem:">Setting up the Optimization Problem:</a></li>
                <li>
                    <a href="#solving-the-optimization-problem" aria-label="Solving the optimization problem">Solving the optimization problem</a></li>
                <li>
                    <a href="#step-by-step-derivation" aria-label="Step-by-Step Derivation:">Step-by-Step Derivation:</a><ul>
                        
                <li>
                    <a href="#1-formulating-the-objective" aria-label="1. Formulating the Objective:">1. Formulating the Objective:</a></li>
                <li>
                    <a href="#2-setting-the-constraint" aria-label="2. Setting the Constraint:">2. Setting the Constraint:</a></li>
                <li>
                    <a href="#3-setting-up-the-lagrangian" aria-label="3. Setting up the Lagrangian:">3. Setting up the Lagrangian:</a></li>
                <li>
                    <a href="#4-taking-the-derivative-of-the-lagrangian" aria-label="4. Taking the Derivative of the Lagrangian:">4. Taking the Derivative of the Lagrangian:</a><ul>
                        
                <li>
                    <a href="#a-derivative-wrt--delta-mathbfw-" aria-label="a. Derivative w.r.t. $ \delta \mathbf{w} $:">a. Derivative w.r.t. $ \delta \mathbf{w} $:</a></li>
                <li>
                    <a href="#b-derivative-wrt--lambda-" aria-label="b. Derivative w.r.t. $ \lambda $:">b. Derivative w.r.t. $ \lambda $:</a></li></ul>
                </li>
                <li>
                    <a href="#5-solving-for--delta-mathbfw-" aria-label="5. Solving for $ \delta \mathbf{w} $:">5. Solving for $ \delta \mathbf{w} $:</a></li>
                <li>
                    <a href="#6-solving-for--lambda-" aria-label="6. Solving for $ \lambda $:">6. Solving for $ \lambda $:</a></li>
                <li>
                    <a href="#7-substitute--lambda--back-into--delta-mathbfw-" aria-label="7. Substitute $ \lambda $ Back into $ \delta \mathbf{w} $:">7. Substitute $ \lambda $ Back into $ \delta \mathbf{w} $:</a></li></ul>
                </li>
                <li>
                    <a href="#finding--delta-w-" aria-label="Finding $ \delta w $">Finding $ \delta w $</a></li>
                <li>
                    <a href="#final-change-in-error--l_q-" aria-label="Final Change in Error ($ L_q $)">Final Change in Error ($ L_q $)</a></li>
                <li>
                    <a href="#2-optimal-brain-quantization-obq" aria-label="2. Optimal Brain Quantization (OBQ)">2. Optimal Brain Quantization (OBQ)</a><ul>
                        
                <li>
                    <a href="#21-row-wise-independent-quantization" aria-label="2.1. Row-wise Independent Quantization">2.1. Row-wise Independent Quantization</a></li>
                <li>
                    <a href="#22-quadratic-formulation" aria-label="2.2. Quadratic Formulation">2.2. Quadratic Formulation</a></li>
                <li>
                    <a href="#23-greedy-quantization" aria-label="2.3. Greedy Quantization">2.3. Greedy Quantization</a></li>
                <li>
                    <a href="#24-mathematical-derivation" aria-label="2.4. Mathematical Derivation">2.4. Mathematical Derivation</a></li></ul>
                </li>
                <li>
                    <a href="#3-limitations-of-obq" aria-label="3. Limitations of OBQ">3. Limitations of OBQ</a></li>
                <li>
                    <a href="#4-gptq-algorithm" aria-label="4. GPTQ Algorithm">4. GPTQ Algorithm</a><ul>
                        
                <li>
                    <a href="#41-arbitrary-quantization-order" aria-label="4.1. Arbitrary Quantization Order">4.1. Arbitrary Quantization Order</a></li>
                <li>
                    <a href="#42-shared-hessian-inverse" aria-label="4.2. Shared Hessian Inverse">4.2. Shared Hessian Inverse</a></li>
                <li>
                    <a href="#43-lazy-batch-updates" aria-label="4.3. Lazy Batch Updates">4.3. Lazy Batch Updates</a></li>
                <li>
                    <a href="#44-cholesky-decomposition" aria-label="4.4. Cholesky Decomposition">4.4. Cholesky Decomposition</a></li></ul>
                </li>
                <li>
                    <a href="#5-mathematical-details" aria-label="5. Mathematical Details">5. Mathematical Details</a><ul>
                        
                <li>
                    <a href="#51-hessian-matrix--mathbfh-" aria-label="5.1. Hessian Matrix $ \mathbf{H} $">5.1. Hessian Matrix $ \mathbf{H} $</a></li>
                <li>
                    <a href="#52-inverse-hessian--mathbfh-1-" aria-label="5.2. Inverse Hessian $ \mathbf{H}^{-1} $">5.2. Inverse Hessian $ \mathbf{H}^{-1} $</a></li>
                <li>
                    <a href="#53-cholesky-decomposition" aria-label="5.3. Cholesky Decomposition">5.3. Cholesky Decomposition</a></li></ul>
                </li>
                <li>
                    <a href="#6-gptq-algorithm-steps" aria-label="6. GPTQ Algorithm Steps">6. GPTQ Algorithm Steps</a><ul>
                        
                <li>
                    <a href="#61-initialization" aria-label="6.1. Initialization">6.1. Initialization</a></li>
                <li>
                    <a href="#62-quantization-loop" aria-label="6.2. Quantization Loop">6.2. Quantization Loop</a></li></ul>
                </li>
                <li>
                    <a href="#7-example" aria-label="7. Example">7. Example</a></li>
                <li>
                    <a href="#8-understanding-the-hessian-in-pre-trained-models" aria-label="8. Understanding the Hessian in Pre-trained Models">8. Understanding the Hessian in Pre-trained Models</a><ul>
                        
                <li>
                    <a href="#81-source-of-the-hessian" aria-label="8.1. Source of the Hessian">8.1. Source of the Hessian</a></li>
                <li>
                    <a href="#82-interpretation" aria-label="8.2. Interpretation">8.2. Interpretation</a></li>
                <li>
                    <a href="#83-hessian-computation-in-practice" aria-label="8.3. Hessian Computation in Practice">8.3. Hessian Computation in Practice</a></li></ul>
                </li>
                <li>
                    <a href="#9-cholesky-decomposition-in-detail" aria-label="9. Cholesky Decomposition in Detail">9. Cholesky Decomposition in Detail</a><ul>
                        
                <li>
                    <a href="#91-mathematical-background" aria-label="9.1. Mathematical Background">9.1. Mathematical Background</a></li>
                <li>
                    <a href="#92-computation-steps" aria-label="9.2. Computation Steps">9.2. Computation Steps</a></li>
                <li>
                    <a href="#93-significance-in-gptq" aria-label="9.3. Significance in GPTQ">9.3. Significance in GPTQ</a></li></ul>
                </li>
                <li>
                    <a href="#10-conclusion" aria-label="10. Conclusion">10. Conclusion</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><strong>Introduction</strong></p>
<p>Quantization is a crucial technique in deep learning that reduces the memory footprint and computational requirements of neural networks by representing weights and activations with lower-precision numerical formats. This is particularly important when deploying large models on devices with limited resources. However, quantizing a neural network without significantly degrading its performance is challenging.</p>
<p>The GPTQ (Gradient Post-Training Quantization) algorithm is a method designed to efficiently quantize large-scale neural networks, such as those used in natural language processing, while maintaining high accuracy. GPTQ builds upon previous methods like Optimal Brain Quantization (OBQ) but introduces significant modifications to make it scalable to models with billions of parameters.</p>
<p>In this explanation, we will delve into the mathematical foundations of GPTQ, starting with the Optimal Brain Sergeon. xplai&hellip;.. how it leverages the Hessian matrix and its inverse, discuss the role of the Cholesky decomposition, and provide a detailed walkthrough of the algorithm. We will also include examples to illustrate key concepts.</p>
<hr>
<h3 id="1-problem-statement"><strong>1. Problem Statement</strong><a hidden class="anchor" aria-hidden="true" href="#1-problem-statement">#</a></h3>
<p>Given a pre-trained neural network, our goal is to quantize its weights so that the network&rsquo;s output remains as close as possible to that of the original network when processing a set of inputs. Specifically, for a linear (fully connected) layer, we aim to find a quantized weight matrix $ \mathbf{W}_c $ that minimizes the reconstruction error.</p>
<p><strong>Mathematically</strong>, the objective is:</p>
<p>$$
\underset{\mathbf{W}_c}{\text{argmin}} , | \mathbf{W}\mathbf{X} - \mathbf{W}_c \mathbf{X} |_2^2
$$</p>
<ul>
<li>$ \mathbf{W} $: Original full-precision weight matrix of the layer.</li>
<li>$ \mathbf{W}_c $: Quantized weight matrix we want to find.</li>
<li>$ \mathbf{X} $: Input matrix to the layer (a set of $ m $ input examples).</li>
<li>$ | \cdot |_2 $: Frobenius norm, summing over all elements. (similar to enclidian norm for vectors)</li>
</ul>
<p><strong>Goal</strong>: Find $ \mathbf{W}_c $ that minimizes the output difference caused by quantization.</p>
<hr>
<p>One of the earlier methods proposed to solve this problem is the OBS (Optimal Brain Sergeon) approach. The GPTQ algorithm is base on the OBQ(Optimal Brain Quantization), which in turn is based on the OBS(Optimal Brain Sergeon) paper, and most of the Equantions prsent in the GPTQ papers are taken from the OBS Paper, so if you want to understand how the weights are quantized and where do these complex formulas come from, you need to First understand the OBS Paper.</p>
<p>The meat of the OBS Paper is a Problem of Constrained Optimization, so i will provide a breifoverview of COnstrained opimization and some relevant formulas for understanding the topics ahead.
(This post assumes that you are familiar wiht terms like gradient and Hessians, and this is not the first time you are hearing the term optimaization and Taylor series)</p>
<h2 id="a-quick-refresher-on-constrained-optimaizaiton">A Quick Refresher on Constrained Optimaizaiton<a hidden class="anchor" aria-hidden="true" href="#a-quick-refresher-on-constrained-optimaizaiton">#</a></h2>
<h3 id="problem-setup">Problem Setup:<a hidden class="anchor" aria-hidden="true" href="#problem-setup">#</a></h3>
<p>You have two things in a constrained optimization problem:</p>
<ol>
<li><strong>Objective function</strong> $ f(x) $ — the function you want to maximize or minimize.</li>
<li><strong>Constraint</strong> $ g(x) = 0 $ — an equation that defines the condition your solution must satisfy.</li>
</ol>
<p>Mathematically, the goal is to:
$$
\text{Minimize } f(x) \quad \text{subject to } g(x) = 0
$$</p>
<h3 id="lagrange-multipliers">Lagrange Multipliers:<a hidden class="anchor" aria-hidden="true" href="#lagrange-multipliers">#</a></h3>
<p>To solve this problem, we introduce a new variable, called a <strong>Lagrange multiplier</strong>, denoted as $ \lambda $. The idea is to combine the objective function and the constraint into a single equation, called the <strong>Lagrangian</strong>:</p>
<p>$$
\mathcal{L}(x, \lambda) = f(x) + \lambda g(x)
$$</p>
<ul>
<li>Here, $ f(x) $ is the objective function.</li>
<li>$ g(x) = 0 $ is the constraint.</li>
<li>$ \lambda $ is the Lagrange multiplier, which &ldquo;enforces&rdquo; the constraint.</li>
</ul>
<hr>
<h3 id="why-does-this-work-super-optional-read-if-intrested">Why Does This Work? (Super Optional: Read if Intrested&hellip;.)<a hidden class="anchor" aria-hidden="true" href="#why-does-this-work-super-optional-read-if-intrested">#</a></h3>
<p>The logic behind this is that at the optimal point under the constraint, the gradient of the objective function $ \nabla f(x) $ must be aligned with the gradient of the constraint $ \nabla g(x) $.</p>
<h4 id="why-are-the-gradients-aligned"><strong>Why Are the Gradients Aligned?</strong><a hidden class="anchor" aria-hidden="true" href="#why-are-the-gradients-aligned">#</a></h4>
<h4 id="1-the-gradient-and-direction-of-steepest-ascent"><strong>1. The Gradient and Direction of Steepest Ascent</strong><a hidden class="anchor" aria-hidden="true" href="#1-the-gradient-and-direction-of-steepest-ascent">#</a></h4>
<ul>
<li>
<p><strong>Gradient of a Function ($ \nabla f(x) $)</strong>: Points in the direction of the steepest increase of the function $ f(x) $ at point $ x $.</p>
</li>
<li>
<p><strong>Constraint Surface ($ g(x) = 0 $)</strong>: Defines a surface (or curve) in the space of $ x $. Any movement along this surface keeps $ g(x) $ constant.</p>
</li>
</ul>
<h4 id="2-feasible-directions-and-tangent-space"><strong>2. Feasible Directions and Tangent Space</strong><a hidden class="anchor" aria-hidden="true" href="#2-feasible-directions-and-tangent-space">#</a></h4>
<ul>
<li>
<p><strong>Feasible Directions</strong>: Directions in which you can move without violating the constraint $ g(x) = 0 $. These directions lie in the <strong>tangent space</strong> of the constraint surface at point $ x $.</p>
</li>
<li>
<p><strong>Tangent Space</strong>: The set of all vectors $ d $ such that $ \nabla g(x)^\top d = 0 $. This means moving a small amount $ \epsilon d $ keeps you on the constraint surface to first order.</p>
</li>
</ul>
<h4 id="3-optimality-condition-under-constraint"><strong>3. Optimality Condition Under Constraint</strong><a hidden class="anchor" aria-hidden="true" href="#3-optimality-condition-under-constraint">#</a></h4>
<ul>
<li>
<p>At the <strong>optimal point</strong>, you cannot find a feasible direction $ d $ that will further decrease $ f(x) $.</p>
</li>
<li>
<p><strong>Mathematically</strong>: The directional derivative of $ f $ in any feasible direction $ d $ must be zero:
$$
\nabla f(x)^\top d = 0 \quad \text{for all } d \text{ such that } \nabla g(x)^\top d = 0
$$</p>
</li>
</ul>
<h4 id="4-gradients-must-be-parallel"><strong>4. Gradients Must Be Parallel</strong><a hidden class="anchor" aria-hidden="true" href="#4-gradients-must-be-parallel">#</a></h4>
<ul>
<li>
<p>The only way for $ \nabla f(x)^\top d = 0 $ for all feasible $ d $ is if $ \nabla f(x) $ is a <strong>linear combination</strong> of $ \nabla g(x) $.</p>
</li>
<li>
<p><strong>Conclusion</strong>: There exists a scalar $ \lambda $ such that:
$$
\nabla f(x) = -\lambda \nabla g(x)
$$
This means $ \nabla f(x) $ and $ \nabla g(x) $ are <strong>aligned</strong> (parallel or antiparallel).</p>
</li>
</ul>
<hr>
<h3 id="steps-to-solve">Steps to Solve:<a hidden class="anchor" aria-hidden="true" href="#steps-to-solve">#</a></h3>
<ol>
<li>
<p><strong>Form the Lagrangian</strong>: As mentioned earlier, combine the objective and constraint:
$$
\mathcal{L}(x, \lambda) = f(x) + \lambda g(x)
$$</p>
</li>
<li>
<p><strong>Take Partial Derivatives</strong>:</p>
<ul>
<li>Take the derivative of $ \mathcal{L} $ with respect to $ x $ (the variables in your objective function).</li>
<li>Take the derivative of $ \mathcal{L} $ with respect to $ \lambda $.</li>
</ul>
</li>
<li>
<p><strong>Set Derivatives to Zero</strong>:
$$
\frac{\partial \mathcal{L}}{\partial x} = 0 \quad \text{and} \quad \frac{\partial \mathcal{L}}{\partial \lambda} = 0
$$
The first condition ensures that the gradients of $ f(x) $ and $ g(x) $ are aligned, and the second condition ensures that the constraint $ g(x) = 0 $ is satisfied.</p>
</li>
<li>
<p><strong>Solve the System of Equations</strong>:
You now have a system of equations involving $ x $ and $ \lambda $. Solve this system to find the optimal values of $ x $ (and $ \lambda $, though you usually don’t care about its value directly).</p>
</li>
</ol>
<h3 id="a-quick-review-of-taylor-series">A quick review of Taylor Series<a hidden class="anchor" aria-hidden="true" href="#a-quick-review-of-taylor-series">#</a></h3>
<p>A function $f(x + \Delta {x})$ may be Taylor expanded about a base point $x$ (if $f$ is differentiable at $x$):</p>
<p>$$
f(x + \Delta {x}) = f(x) + \frac{d f(x)}{d {x}} \Delta {x} + \frac{d^2 f(x)}{d {x}^2} \frac{\Delta {x}^2}{2!} + \dots
$$</p>
<p>We don&rsquo;t deal with scalars (anymore!)</p>
<p>$$
f(\mathbf{x} + \Delta \mathbf{x}) = f(\mathbf{x}) + \nabla f(\mathbf{x}) \cdot \Delta \mathbf{x} + \frac{1}{2!} \Delta \mathbf{x}^T H(f(\mathbf{x})) \Delta \mathbf{x} + \dots
$$</p>
<ul>
<li>$\nabla f(\mathbf{x})$ = gradient of $f$ at $\mathbf{x}$, a vector of partial derivatives</li>
</ul>
<p>$$
\nabla f(\mathbf{x}) = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \dots, \frac{\partial f}{\partial x_n} \right)
$$</p>
<ul>
<li>$H(f(\mathbf{x}))$ = second-order partial derivatives of $f$ at $\mathbf{x}$, with elements $H_{ij} = \frac{\partial^2 f}{\partial x_i \partial x_j}$</li>
</ul>
<p>$$
\Delta \mathbf{x}^T H(f(\mathbf{x})) \Delta \mathbf{x}
$$
is a quadratic form, this term computes how much the function curves in the direction of $\Delta \mathbf{x}$, weighted by the second derivatives (Hessian).</p>
<p>Phew, we are done with our Background so lets Begin</p>
<h2 id="obs-optimnal-brain-surgery">OBS (Optimnal Brain Surgery)<a hidden class="anchor" aria-hidden="true" href="#obs-optimnal-brain-surgery">#</a></h2>
<h3 id="overview">Overview<a hidden class="anchor" aria-hidden="true" href="#overview">#</a></h3>
<p>OBS is a method for pruning neural networks by removing weights while minimizing the increase in the loss fuction. It uses secone order (Hessian ) information to identify which weights can be pruned with minimal impact on performance.</p>
<h3 id="problem-context">Problem Context<a hidden class="anchor" aria-hidden="true" href="#problem-context">#</a></h3>
<p>In a neural network, each weight $ w_p $ contributes to the overall performance (or loss) of the model. If you want to <strong>remove</strong> a weight (i.e., prune it), there is a chance that this removal will negatively affect the network&rsquo;s performance, causing the loss function to increase.</p>
<p>To avoid large increases in the loss function, OBS prunes weights in a <strong>careful, optimized way</strong>. The goal is to find which weight(s) can be removed and adjust the other weights such that the <strong>impact on the loss function is minimal</strong>.</p>
<h3 id="optimization-problem">Optimization Problem<a hidden class="anchor" aria-hidden="true" href="#optimization-problem">#</a></h3>
<p>This all sounds great, but how is this an optimization problem?
When you prune a weight, it affects the entire neural network. Simply setting a weight to zero will not work well unless you <strong>adjust the other weights</strong> in the network to compensate for the change. This adjustment of weights forms an optimization problem:</p>
<ul>
<li><strong>Objective:</strong> Minimize the <strong>increase in the loss function</strong> caused by pruning.</li>
<li><strong>Constraint:</strong> Set the specific weight $ w_p $ to zero (i.e., prune it).</li>
</ul>
<p>This optimization problem helps find the best way to modify the remaining weights while ensuring the selected weight is removed.</p>
<h3 id="mathematical-formulation">Mathematical Formulation<a hidden class="anchor" aria-hidden="true" href="#mathematical-formulation">#</a></h3>
<p>The loss function $ L(\mathbf{w}) $ of a neural network depends on the weights $ \mathbf{w} = [w_1, w_2, \dots, w_n] $. When we prune a weight, we want to minimize the change in the loss function, specifically:</p>
<p>$$
\Delta L = L(\mathbf{w} + \delta \mathbf{w}) - L(\mathbf{w})
$$</p>
<p>$
\mathbf{w} \in \mathbb{R}^n \quad \text{original set of weights}
$</p>
<p>$
\delta\mathbf{w} \in \mathbb{R}^n \quad \text{change applied to the weights}
$ (In case of pruning a specific weight $w_p$, $\delta w_p$ would be a negative value)$ \delta w_p = -w_p $</p>
<p>2nd order Taylor Series Expansion</p>
<p>$$
L(\mathbf{w} + \delta \mathbf{w}) = L(\mathbf{w}) + \nabla L(\mathbf{w})^T \delta \mathbf{w} + \frac{1}{2} \delta \mathbf{w}^T H \delta \mathbf{w}
$$</p>
<p><strong>Neglecting the gradient!!!</strong>, this is someting that we genrally dont do, (we generally ignore the first derivative)</p>
<p>In practice, when we are pruning weights, we assume the network is already near a local minimum (already trained), so the gradient $\nabla L(\mathbf{w})$ is close to 0. This simplifies the expression.</p>
<p>$$
\Delta L = L(\mathbf{w}) + \nabla L(\mathbf{w})^T \delta \mathbf{w} + \frac{1}{2} \delta \mathbf{w}^T H \delta \mathbf{w} - L(\mathbf{w})
$$</p>
<p>Therefore,</p>
<p>$$
\Delta L = \frac{1}{2} \delta \mathbf{w}^T H \delta \mathbf{w}
$$</p>
<h3 id="setting-up-the-optimization-problem"><strong>Setting up the Optimization Problem:</strong><a hidden class="anchor" aria-hidden="true" href="#setting-up-the-optimization-problem">#</a></h3>
<p>The optimization problem becomes:</p>
<p>$$
\min_{\delta \mathbf{w}} \frac{1}{2} \delta \mathbf{w}^\top H \delta \mathbf{w}
$$</p>
<p>Subject to the constraint:</p>
<p>$$
\delta w_p = -w_p
$$</p>
<p>This constraint enforces the pruning of the weight $ w_p $, meaning we want the change in $ w_p $ to be exactly $ -w_p $ so that the new value becomes zero (i.e., $ w_p + \delta w_p = 0 $).</p>
<h3 id="solving-the-optimization-problem">Solving the optimization problem<a hidden class="anchor" aria-hidden="true" href="#solving-the-optimization-problem">#</a></h3>
<h3 id="step-by-step-derivation">Step-by-Step Derivation:<a hidden class="anchor" aria-hidden="true" href="#step-by-step-derivation">#</a></h3>
<h4 id="1-formulating-the-objective">1. <strong>Formulating the Objective:</strong><a hidden class="anchor" aria-hidden="true" href="#1-formulating-the-objective">#</a></h4>
<p>The objective is to <strong>minimize</strong> the increase in the loss function due to weight pruning.</p>
<p>$$
\min_{\delta \mathbf{w}} \frac{1}{2} \delta \mathbf{w}^\top H \delta \mathbf{w}
$$</p>
<p>Here:</p>
<ul>
<li>$ \delta \mathbf{w} $ represents the change in the weights.</li>
<li>$ H $ is the Hessian matrix, which gives the second-order approximation of how the loss function changes with respect to the weights.</li>
</ul>
<h4 id="2-setting-the-constraint">2. <strong>Setting the Constraint:</strong><a hidden class="anchor" aria-hidden="true" href="#2-setting-the-constraint">#</a></h4>
<p>When we prune a specific weight $ w_p $, the change in that weight should be exactly $ -w_p $ to set it to zero:</p>
<p>$$
\delta w_p = -w_p
$$</p>
<p>In vector form, this constraint can be written as:</p>
<p>$$
\mathbf{e}_p^T \delta \mathbf{w} + w_p = 0
$$</p>
<p>where $ \mathbf{e}_p $ is the one hot vector corresponding to the weight $ w_q $.</p>
<p>This ensures that the weight $ w_p $ is fully pruned.</p>
<h4 id="3-setting-up-the-lagrangian">3. <strong>Setting up the Lagrangian:</strong><a hidden class="anchor" aria-hidden="true" href="#3-setting-up-the-lagrangian">#</a></h4>
<p>To handle this constraint, we introduce a <strong>Lagrange multiplier</strong> $ \lambda $. The Lagrangian $ \mathcal{L} $ combines the objective function and the constraint:</p>
<p>$$
\mathcal{L}(\delta \mathbf{w}, \lambda) = \frac{1}{2} \delta \mathbf{w}^\top H \delta \mathbf{w} + \lambda (\mathbf{e}_p^T \delta \mathbf{w} + w_p)
$$</p>
<p>Where:</p>
<ul>
<li>The term $ \lambda (\mathbf{e}_p^T \delta \mathbf{w} + w_p) $ enforces the constraint that $ \delta w_p = -w_p $.</li>
<li>$ \lambda $ is the Lagrange multiplier.</li>
</ul>
<h4 id="4-taking-the-derivative-of-the-lagrangian">4. <strong>Taking the Derivative of the Lagrangian:</strong><a hidden class="anchor" aria-hidden="true" href="#4-taking-the-derivative-of-the-lagrangian">#</a></h4>
<p>To minimize the Lagrangian, we take the derivative with respect to the change in weights $ \delta \mathbf{w} $ and the Lagrange multiplier $ \lambda $.</p>
<h5 id="a-derivative-wrt--delta-mathbfw-">a. <strong>Derivative w.r.t. $ \delta \mathbf{w} $:</strong><a hidden class="anchor" aria-hidden="true" href="#a-derivative-wrt--delta-mathbfw-">#</a></h5>
<p>$$
\frac{\partial \mathcal{L}}{\partial \delta \mathbf{w}} = H \delta \mathbf{w} + \lambda \mathbf{e}_p = 0
$$</p>
<p>Here:</p>
<ul>
<li>$ e_p $ is a vector with a 1 in the $ p $-th position (corresponding to $ w_p $) and 0 elsewhere, as the constraint only applies to the $ p $-th weight.</li>
<li>Solving this gives:</li>
</ul>
<p>$$
H \delta \mathbf{w} = -\lambda \mathbf{e}_p
$$</p>
<h5 id="b-derivative-wrt--lambda-">b. <strong>Derivative w.r.t. $ \lambda $:</strong><a hidden class="anchor" aria-hidden="true" href="#b-derivative-wrt--lambda-">#</a></h5>
<p>$$
\frac{\partial \mathcal{L}}{\partial \lambda} = \delta w_p + w_p = 0
$$</p>
<p>This gives us the constraint:</p>
<p>$$
\delta w_p = -w_p
$$</p>
<h4 id="5-solving-for--delta-mathbfw-">5. <strong>Solving for $ \delta \mathbf{w} $:</strong><a hidden class="anchor" aria-hidden="true" href="#5-solving-for--delta-mathbfw-">#</a></h4>
<p>From the equation $ H \delta \mathbf{w} = -\frac{\lambda}{2} e_p $, we can solve for $ \delta \mathbf{w} $ by multiplying both sides by the inverse of $ H $:</p>
<p>$$
\delta \mathbf{w} = -\frac{\lambda}{2} H^{-1} e_p
$$</p>
<p>The vector $ H^{-1} e_p $ represents the $ p $-th column of the inverse of the Hessian matrix $ H $.</p>
<h4 id="6-solving-for--lambda-">6. <strong>Solving for $ \lambda $:</strong><a hidden class="anchor" aria-hidden="true" href="#6-solving-for--lambda-">#</a></h4>
<p>We now use the constraint $ \delta w_p = -w_p $ to solve for $ \lambda $.</p>
<p>From $ \delta w_p = e_p^\top \delta \mathbf{w} = -w_p $, we substitute $ \delta \mathbf{w} $:</p>
<p>$$
e_p^\top \left( -\frac{\lambda}{2} H^{-1} e_p \right) = -w_p
$$</p>
<p>This simplifies to:</p>
<p>$$
-\frac{\lambda}{2} [H^{-1}]_{pp} = -w_p
$$</p>
<p>Solving for $ \lambda $:</p>
<p>$$
\lambda = \frac{2 w_p}{[H^{-1}]_{pp}}
$$</p>
<h4 id="7-substitute--lambda--back-into--delta-mathbfw-">7. <strong>Substitute $ \lambda $ Back into $ \delta \mathbf{w} $:</strong><a hidden class="anchor" aria-hidden="true" href="#7-substitute--lambda--back-into--delta-mathbfw-">#</a></h4>
<p>Now, substitute $ \lambda $ back into the expression for $ \delta \mathbf{w} $:</p>
<p>$$
\delta \mathbf{w} = -\frac{w_p}{[H^{-1}]_{pp}} H^{-1} e_p
$$</p>
<p>This equation gives the <strong>update to the remaining weights</strong> after pruning $ w_p $.</p>
<h3 id="finding--delta-w-">Finding $ \delta w $<a hidden class="anchor" aria-hidden="true" href="#finding--delta-w-">#</a></h3>
<p>Now, substitute $ \lambda $ back into the expression for $ \delta w $:</p>
<p>$$
\delta w = -\frac{w_q}{e_q^T H^{-1} e_q} H^{-1} e_q
$$</p>
<p>This is the optimal weight change that minimizes the increase in error while setting $ w_q $ to zero.</p>
<h3 id="final-change-in-error--l_q-">Final Change in Error ($ L_q $)<a hidden class="anchor" aria-hidden="true" href="#final-change-in-error--l_q-">#</a></h3>
<p>Now, we compute the resulting change in error $ \delta E $ by substituting $ \delta w $ into the second-order Taylor expansion of the error function:</p>
<p>$$
\delta E = \frac{1}{2} \delta w^T H \delta w
$$</p>
<p>Substitute $ \delta w = -\frac{w_q}{e_q^T H^{-1} e_q} H^{-1} e_q $ into this:</p>
<p>$$
\delta E = \frac{1}{2} \left(-\frac{w_q}{e_q^T H^{-1} e_q} H^{-1} e_q \right)^T H \left(-\frac{w_q}{e_q^T H^{-1} e_q} H^{-1} e_q \right)
$$</p>
<p>Simplifying:</p>
<p>$$
\delta E = \frac{1}{2} \frac{w_q^2}{(e_q^T H^{-1} e_q)^2} \left( e_q^T H^{-1} H H^{-1} e_q \right)
$$</p>
<p>Since $ H^{-1} H = I $, this becomes:</p>
<p>$$
\delta E = \frac{1}{2} \frac{w_q^2}{e_q^T H^{-1} e_q}
$$</p>
<p>This is the final expression for the change in error due to setting $ w_q $ to zero, which we denote as $ L_q $:</p>
<p>$$
L_q = \frac{1}{2} \frac{w_q^2}{(H^{-1})_{qq}}
$$</p>
<p>where $ (H^{-1})_{qq} = e_q^T H^{-1} e_q $ is the diagonal element of the inverse Hessian matrix corresponding to weight $ w_q $. This final equation represents the &ldquo;saliency&rdquo; or importance of weight $ w_q $ in the network.</p>
<h3 id="2-optimal-brain-quantization-obq"><strong>2. Optimal Brain Quantization (OBQ)</strong><a hidden class="anchor" aria-hidden="true" href="#2-optimal-brain-quantization-obq">#</a></h3>
<h4 id="21-row-wise-independent-quantization"><strong>2.1. Row-wise Independent Quantization</strong><a hidden class="anchor" aria-hidden="true" href="#21-row-wise-independent-quantization">#</a></h4>
<p>OBQ simplifies the problem by treating each row $ \mathbf{w} $ of $ \mathbf{W} $ independently. This is reasonable because in a fully connected layer, each output neuron corresponds to one row of $ \mathbf{W} $, and the neurons operate independently given the inputs.</p>
<p><strong>Objective per row</strong>:</p>
<p>$$
\underset{\mathbf{w}_c}{\text{argmin}} , | \mathbf{w}\mathbf{X} - \mathbf{w}_c \mathbf{X} |_2^2
$$</p>
<h4 id="22-quadratic-formulation"><strong>2.2. Quadratic Formulation</strong><a hidden class="anchor" aria-hidden="true" href="#22-quadratic-formulation">#</a></h4>
<p>The error for each row can be expressed as:</p>
<p>$$
E(\mathbf{w}_c) = | \mathbf{w}\mathbf{X} - \mathbf{w}_c \mathbf{X} |_2^2 = (\mathbf{w} - \mathbf{w}_c) \mathbf{H} (\mathbf{w} - \mathbf{w}_c)^\top
$$</p>
<p>Where:</p>
<ul>
<li>$ \mathbf{H} = \mathbf{X}\mathbf{X}^\top $: The Hessian matrix for this quadratic form.</li>
<li>$ \mathbf{w} $: Original weights (vector).</li>
<li>$ \mathbf{w}_c $: Quantized weights (vector).</li>
</ul>
<p>The Hessian $ \mathbf{H} $ captures the second-order derivatives of the error with respect to $ \mathbf{w}_c $.</p>
<h4 id="23-greedy-quantization"><strong>2.3. Greedy Quantization</strong><a hidden class="anchor" aria-hidden="true" href="#23-greedy-quantization">#</a></h4>
<p>OBQ quantizes one weight at a time:</p>
<ol>
<li>
<p><strong>Select weight to quantize</strong>: Choose the weight that, when quantized, results in the smallest increase in the error $ E $.</p>
</li>
<li>
<p><strong>Update remaining weights</strong>: Adjust the unquantized weights to compensate for the error introduced by quantizing the selected weight.</p>
</li>
</ol>
<h4 id="24-mathematical-derivation"><strong>2.4. Mathematical Derivation</strong><a hidden class="anchor" aria-hidden="true" href="#24-mathematical-derivation">#</a></h4>
<p><strong>Step 1: Quantization Error for a Single Weight</strong></p>
<p>Let’s consider quantizing the $ q $-th weight $ w_q $ in $ \mathbf{w} $:</p>
<p>$$
\delta w_q = w_q - \text{quant}(w_q)
$$</p>
<p>The change in the error due to quantizing $ w_q $ is:</p>
<p>$$
\Delta E = (\delta w_q)^2 H_{qq}
$$</p>
<p>Where $ H_{qq} $ is the $ q $-th diagonal element of $ \mathbf{H} $.</p>
<p><strong>Step 2: Updating Remaining Weights</strong></p>
<p>To minimize the error, we adjust the remaining unquantized weights $ \mathbf{w}_F $:</p>
<p>$$
\delta \mathbf{w}<em>F = -\frac{\delta w_q}{H</em>{qq}} \mathbf{H}_{Fq}
$$</p>
<ul>
<li>$ \mathbf{H}_{Fq} $: The $ q $-th column (excluding $ q $-th row) of $ \mathbf{H} $.</li>
</ul>
<p>This adjustment aims to compensate for the error introduced by quantizing $ w_q $.</p>
<p><strong>Step 3: Update Hessian Inverse</strong></p>
<p>After quantizing $ w_q $, we need to update the inverse Hessian $ \mathbf{H}_F^{-1} $ for the remaining weights:</p>
<p>$$
\mathbf{H}_F^{-1} \leftarrow \mathbf{H}_F^{-1} - \frac{\mathbf{H}_F^{-1} \mathbf{e}_q \mathbf{e}_q^\top \mathbf{H}<em>F^{-1}}{H</em>{qq}}
$$</p>
<ul>
<li>$ \mathbf{e}_q $: Standard basis vector with 1 at position $ q $ and zeros elsewhere.</li>
</ul>
<p><strong>Note</strong>: This update uses the Sherman-Morrison formula for rank-one updates of matrix inverses.</p>
<hr>
<h3 id="3-limitations-of-obq"><strong>3. Limitations of OBQ</strong><a hidden class="anchor" aria-hidden="true" href="#3-limitations-of-obq">#</a></h3>
<p>While OBQ is effective for small to medium-sized models, it faces challenges with large models:</p>
<ul>
<li>
<p><strong>Computational Complexity</strong>: The algorithm has cubic time complexity $ O(d_{\text{row}} \cdot d_{\text{col}}^3) $, where $ d_{\text{row}} $ and $ d_{\text{col}} $ are the dimensions of $ \mathbf{W} $.</p>
</li>
<li>
<p><strong>Memory Requirements</strong>: Storing and updating the Hessian inverse becomes impractical for layers with millions of parameters.</p>
</li>
</ul>
<hr>
<h3 id="4-gptq-algorithm"><strong>4. GPTQ Algorithm</strong><a hidden class="anchor" aria-hidden="true" href="#4-gptq-algorithm">#</a></h3>
<p>GPTQ introduces several key modifications to make the quantization process scalable:</p>
<h4 id="41-arbitrary-quantization-order"><strong>4.1. Arbitrary Quantization Order</strong><a hidden class="anchor" aria-hidden="true" href="#41-arbitrary-quantization-order">#</a></h4>
<p><strong>Insight</strong>: Quantizing weights in an arbitrary fixed order (e.g., left to right) performs almost as well as the greedy order, especially for large layers.</p>
<p><strong>Benefit</strong>: This allows all rows to quantize weights in the same order, making $ \mathbf{H} $ and its inverse the same across rows.</p>
<h4 id="42-shared-hessian-inverse"><strong>4.2. Shared Hessian Inverse</strong><a hidden class="anchor" aria-hidden="true" href="#42-shared-hessian-inverse">#</a></h4>
<p>Since all rows share the same quantization order, we can compute $ \mathbf{H}^{-1} $ once and use it for all rows.</p>
<ul>
<li><strong>Computational Saving</strong>: Reduces complexity from $ O(d_{\text{row}} \cdot d_{\text{col}}^3) $ to $ O(\max{d_{\text{row}} \cdot d_{\text{col}}^2, d_{\text{col}}^3}) $.</li>
</ul>
<h4 id="43-lazy-batch-updates"><strong>4.3. Lazy Batch Updates</strong><a hidden class="anchor" aria-hidden="true" href="#43-lazy-batch-updates">#</a></h4>
<p>To improve computational efficiency:</p>
<ul>
<li>
<p><strong>Process Blocks</strong>: Quantize weights in blocks of columns (e.g., 128 columns at a time).</p>
</li>
<li>
<p><strong>Batch Updates</strong>: Update $ \mathbf{W} $ and $ \mathbf{H}^{-1} $ after processing each block, rather than after every weight quantization.</p>
</li>
</ul>
<p><strong>Benefit</strong>: Increases the compute-to-memory-access ratio, better utilizing GPU capabilities.</p>
<h4 id="44-cholesky-decomposition"><strong>4.4. Cholesky Decomposition</strong><a hidden class="anchor" aria-hidden="true" href="#44-cholesky-decomposition">#</a></h4>
<p>To address numerical instability:</p>
<ul>
<li>
<p><strong>Observation</strong>: Only certain parts (rows/columns) of $ \mathbf{H}^{-1} $ are needed during quantization.</p>
</li>
<li>
<p><strong>Solution</strong>: Use the Cholesky decomposition of $ \mathbf{H}^{-1} $ to compute necessary components more stably.</p>
</li>
<li>
<p><strong>Cholesky Decomposition</strong>: For a symmetric positive-definite matrix $ \mathbf{A} $, the Cholesky decomposition finds a lower triangular matrix $ \mathbf{L} $ such that $ \mathbf{A} = \mathbf{L} \mathbf{L}^\top $.</p>
</li>
</ul>
<p><strong>Benefit</strong>: Enhances numerical stability and reduces computational errors, especially important for large models.</p>
<hr>
<h3 id="5-mathematical-details"><strong>5. Mathematical Details</strong><a hidden class="anchor" aria-hidden="true" href="#5-mathematical-details">#</a></h3>
<h4 id="51-hessian-matrix--mathbfh-"><strong>5.1. Hessian Matrix $ \mathbf{H} $</strong><a hidden class="anchor" aria-hidden="true" href="#51-hessian-matrix--mathbfh-">#</a></h4>
<p><strong>Definition</strong>:</p>
<p>$$
\mathbf{H} = 2 \mathbf{X} \mathbf{X}^\top + \lambda \mathbf{I}
$$</p>
<ul>
<li>$ \mathbf{X} \in \mathbb{R}^{d_{\text{col}} \times m} $: Input matrix with $ m $ examples.</li>
<li>$ \lambda $: Damping factor added to ensure numerical stability (e.g., $ \lambda = 0.01 \times \text{mean of diagonal elements} $).</li>
<li>$ \mathbf{I} $: Identity matrix.</li>
</ul>
<p><strong>Role</strong>: Captures the curvature of the error function with respect to the weights.</p>
<p><strong>Note</strong>: The factor of 2 arises from the derivative of the squared error.</p>
<h4 id="52-inverse-hessian--mathbfh-1-"><strong>5.2. Inverse Hessian $ \mathbf{H}^{-1} $</strong><a hidden class="anchor" aria-hidden="true" href="#52-inverse-hessian--mathbfh-1-">#</a></h4>
<ul>
<li>
<p><strong>Purpose</strong>: Required to compute the optimal adjustments to the unquantized weights when quantizing a weight.</p>
</li>
<li>
<p><strong>Computation</strong>: Direct inversion is computationally expensive for large matrices.</p>
</li>
</ul>
<h4 id="53-cholesky-decomposition"><strong>5.3. Cholesky Decomposition</strong><a hidden class="anchor" aria-hidden="true" href="#53-cholesky-decomposition">#</a></h4>
<p><strong>Concept</strong>:</p>
<ul>
<li>For a symmetric positive-definite matrix $ \mathbf{A} $, the Cholesky decomposition finds a lower triangular matrix $ \mathbf{L} $ such that:</li>
</ul>
<p>$$
\mathbf{A} = \mathbf{L} \mathbf{L}^\top
$$</p>
<p><strong>Significance</strong>:</p>
<ul>
<li>
<p><strong>Numerical Stability</strong>: More stable than direct inversion or eigenvalue decomposition for positive-definite matrices.</p>
</li>
<li>
<p><strong>Efficient Computation</strong>: Allows solving linear systems $ \mathbf{A}\mathbf{x} = \mathbf{b} $ efficiently by forward and backward substitution.</p>
</li>
</ul>
<p><strong>Application in GPTQ</strong>:</p>
<ul>
<li>
<p>Instead of computing $ \mathbf{H}^{-1} $ directly, compute the Cholesky decomposition $ \mathbf{L} $.</p>
</li>
<li>
<p>Use $ \mathbf{L} $ to compute necessary components of $ \mathbf{H}^{-1} $ when needed.</p>
</li>
</ul>
<hr>
<h3 id="6-gptq-algorithm-steps"><strong>6. GPTQ Algorithm Steps</strong><a hidden class="anchor" aria-hidden="true" href="#6-gptq-algorithm-steps">#</a></h3>
<h4 id="61-initialization"><strong>6.1. Initialization</strong><a hidden class="anchor" aria-hidden="true" href="#61-initialization">#</a></h4>
<ul>
<li><strong>Compute Hessian Matrix</strong>:</li>
</ul>
<p>$$
\mathbf{H} = 2 \mathbf{X} \mathbf{X}^\top + \lambda \mathbf{I}
$$</p>
<ul>
<li><strong>Compute Cholesky Decomposition</strong>:</li>
</ul>
<p>$$
\mathbf{H}^{-1} = (\mathbf{L} \mathbf{L}^\top )^{-1}
$$</p>
<p>However, we don&rsquo;t compute $ \mathbf{H}^{-1} $ explicitly. Instead, we use $ \mathbf{L} $ to solve systems involving $ \mathbf{H}^{-1} $.</p>
<h4 id="62-quantization-loop"><strong>6.2. Quantization Loop</strong><a hidden class="anchor" aria-hidden="true" href="#62-quantization-loop">#</a></h4>
<p>For each block of columns (weights), perform the following:</p>
<p><strong>Step 1: Quantize Weights</strong></p>
<ul>
<li>For each column $ j $ in the block, quantize $ \mathbf{W}_{:, j} $:</li>
</ul>
<p>$$
\mathbf{Q}<em>{:, j} = \text{quant}(\mathbf{W}</em>{:, j})
$$</p>
<ul>
<li>Compute quantization error:</li>
</ul>
<p>$$
\delta \mathbf{W}<em>{:, j} = \mathbf{W}</em>{:, j} - \mathbf{Q}_{:, j}
$$</p>
<p><strong>Step 2: Update Remaining Weights</strong></p>
<ul>
<li>
<p>Adjust unquantized weights to compensate for the error introduced by quantizing the current weight(s).</p>
</li>
<li>
<p>Use the Cholesky factors to compute the necessary adjustments efficiently.</p>
</li>
</ul>
<p><strong>Step 3: Batch Updates</strong></p>
<ul>
<li>After processing the block, update the remaining weights and the relevant parts of $ \mathbf{H}^{-1} $.</li>
</ul>
<p><strong>Algorithm Pseudocode</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>Initialize Q = zeros(d_row, d_col)
</span></span><span style="display:flex;"><span>Compute H = 2 * X * X^T + lambda * I
</span></span><span style="display:flex;"><span>Compute Cholesky decomposition of H^-1: H_inv = Cholesky(H^-1)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>For i in range(0, d_col, block_size):
</span></span><span style="display:flex;"><span>    For j in range(i, i + block_size):
</span></span><span style="display:flex;"><span>        Q[:, j] = quantize(W[:, j])
</span></span><span style="display:flex;"><span>        E[:, j - i] = (W[:, j] - Q[:, j]) / H_inv[j, j]
</span></span><span style="display:flex;"><span>        W[:, j:(i + block_size)] -= E[:, j - i] * H_inv[j, j:(i + block_size)]
</span></span><span style="display:flex;"><span>    W[:, (i + block_size):] -= E * H_inv[i:(i + block_size), (i + block_size):]
</span></span></code></pre></div><hr>
<h3 id="7-example"><strong>7. Example</strong><a hidden class="anchor" aria-hidden="true" href="#7-example">#</a></h3>
<p>Let&rsquo;s illustrate the GPTQ algorithm with a simplified example.</p>
<p><strong>Assumptions</strong>:</p>
<ul>
<li>$ \mathbf{W} $ is a $ 2 \times 2 $ weight matrix.</li>
<li>$ \mathbf{X} $ is a $ 2 \times 3 $ input matrix (3 examples).</li>
<li>We quantize to 1-bit weights (e.g., $-1$ or $+1$).</li>
</ul>
<p><strong>Step 1: Initialize</strong></p>
<ul>
<li><strong>Weights</strong>:</li>
</ul>
<p>$$
\mathbf{W} = \begin{bmatrix} 0.8 &amp; -0.5 \ 0.3 &amp; 0.7 \end{bmatrix}
$$</p>
<ul>
<li><strong>Inputs</strong>:</li>
</ul>
<p>$$
\mathbf{X} = \begin{bmatrix} 0.2 &amp; -0.1 &amp; 0.4 \ 0.5 &amp; 0.3 &amp; -0.2 \end{bmatrix}
$$</p>
<ul>
<li><strong>Compute Hessian</strong>:</li>
</ul>
<p>$$
\mathbf{H} = 2 \mathbf{X} \mathbf{X}^\top + \lambda \mathbf{I}
$$</p>
<p>Compute $ \mathbf{X} \mathbf{X}^\top $:</p>
<p>$$
\mathbf{X} \mathbf{X}^\top = \begin{bmatrix} (0.2)^2 + (-0.1)^2 + (0.4)^2 &amp; 0.2*0.5 + (-0.1)<em>0.3 + 0.4</em>(-0.2) \ \text{Symmetric} &amp; (0.5)^2 + (0.3)^2 + (-0.2)^2 \end{bmatrix}
$$</p>
<p>Compute $ \mathbf{H} $ (assuming $ \lambda = 0 $ for simplicity).</p>
<ul>
<li><strong>Cholesky Decomposition</strong>:</li>
</ul>
<p>Compute $ \mathbf{L} $ such that $ \mathbf{H} = \mathbf{L} \mathbf{L}^\top $.</p>
<p><strong>Step 2: Quantization</strong></p>
<ul>
<li><strong>Quantize $ \mathbf{W} $</strong>:</li>
</ul>
<p>$$
\mathbf{Q} = \begin{bmatrix} \text{quant}(0.8) &amp; \text{quant}(-0.5) \ \text{quant}(0.3) &amp; \text{quant}(0.7) \end{bmatrix} = \begin{bmatrix} 1 &amp; -1 \ 1 &amp; 1 \end{bmatrix}
$$</p>
<ul>
<li><strong>Compute Quantization Error</strong>:</li>
</ul>
<p>$$
\delta \mathbf{W} = \mathbf{W} - \mathbf{Q} = \begin{bmatrix} 0.8 - 1 &amp; -0.5 + 1 \ 0.3 - 1 &amp; 0.7 - 1 \end{bmatrix} = \begin{bmatrix} -0.2 &amp; 0.5 \ -0.7 &amp; -0.3 \end{bmatrix}
$$</p>
<p><strong>Step 3: Update Remaining Weights</strong></p>
<ul>
<li>
<p>Use $ \delta \mathbf{W} $ and $ \mathbf{H}^{-1} $ (via Cholesky factors) to adjust the unquantized weights.</p>
</li>
<li>
<p>For this small example, adjustments are minor.</p>
</li>
</ul>
<hr>
<h3 id="8-understanding-the-hessian-in-pre-trained-models"><strong>8. Understanding the Hessian in Pre-trained Models</strong><a hidden class="anchor" aria-hidden="true" href="#8-understanding-the-hessian-in-pre-trained-models">#</a></h3>
<h4 id="81-source-of-the-hessian"><strong>8.1. Source of the Hessian</strong><a hidden class="anchor" aria-hidden="true" href="#81-source-of-the-hessian">#</a></h4>
<p>In the context of quantization, the Hessian matrix $ \mathbf{H} $ arises from the second-order Taylor expansion of the error function with respect to the weights.</p>
<ul>
<li><strong>Error Function</strong>:</li>
</ul>
<p>$$
E(\mathbf{w}_c) = | \mathbf{w}\mathbf{X} - \mathbf{w}_c \mathbf{X} |_2^2
$$</p>
<ul>
<li><strong>First Derivative</strong>:</li>
</ul>
<p>$$
\frac{\partial E}{\partial \mathbf{w}_c} = -2 (\mathbf{w}\mathbf{X} - \mathbf{w}_c \mathbf{X}) \mathbf{X}^\top
$$</p>
<ul>
<li><strong>Second Derivative (Hessian)</strong>:</li>
</ul>
<p>$$
\mathbf{H} = \frac{\partial^2 E}{\partial \mathbf{w}_c^2} = 2 \mathbf{X} \mathbf{X}^\top
$$</p>
<h4 id="82-interpretation"><strong>8.2. Interpretation</strong><a hidden class="anchor" aria-hidden="true" href="#82-interpretation">#</a></h4>
<ul>
<li>
<p>$ \mathbf{H} $ captures how sensitive the error is to changes in $ \mathbf{w}_c $.</p>
</li>
<li>
<p>In quantization, we are interested in how quantizing a weight affects the overall error, and $ \mathbf{H} $ provides this information.</p>
</li>
</ul>
<h4 id="83-hessian-computation-in-practice"><strong>8.3. Hessian Computation in Practice</strong><a hidden class="anchor" aria-hidden="true" href="#83-hessian-computation-in-practice">#</a></h4>
<ul>
<li>
<p>For large models, computing $ \mathbf{H} $ directly is impractical.</p>
</li>
<li>
<p><strong>Approximation</strong>: Use a subset of data ($ m $ examples) to compute $ \mathbf{X} $ and hence $ \mathbf{H} $.</p>
</li>
<li>
<p><strong>Regularization</strong>: Add damping ($ \lambda \mathbf{I} $) to $ \mathbf{H} $ to ensure it is positive-definite and invertible.</p>
</li>
</ul>
<hr>
<h3 id="9-cholesky-decomposition-in-detail"><strong>9. Cholesky Decomposition in Detail</strong><a hidden class="anchor" aria-hidden="true" href="#9-cholesky-decomposition-in-detail">#</a></h3>
<h4 id="91-mathematical-background"><strong>9.1. Mathematical Background</strong><a hidden class="anchor" aria-hidden="true" href="#91-mathematical-background">#</a></h4>
<ul>
<li><strong>Definition</strong>: For a symmetric positive-definite matrix $ \mathbf{A} $, there exists a unique lower triangular matrix $ \mathbf{L} $ with positive diagonal elements such that:</li>
</ul>
<p>$$
\mathbf{A} = \mathbf{L} \mathbf{L}^\top
$$</p>
<h4 id="92-computation-steps"><strong>9.2. Computation Steps</strong><a hidden class="anchor" aria-hidden="true" href="#92-computation-steps">#</a></h4>
<ol>
<li>
<p><strong>Initialization</strong>:</p>
<ul>
<li>Let $ \mathbf{A} $ be $ n \times n $.</li>
<li>$ \mathbf{L} $ is initialized as a zero matrix.</li>
</ul>
</li>
<li>
<p><strong>Algorithm</strong>:</p>
<p>For $ i = 1 $ to $ n $:</p>
<ul>
<li>
<p>Compute:</p>
<p>$$
L_{ii} = \sqrt{A_{ii} - \sum_{k=1}^{i-1} L_{ik}^2}
$$</p>
</li>
<li>
<p>For $ j = i+1 $ to $ n $:</p>
<p>$$
L_{ji} = \frac{1}{L_{ii}} \left( A_{ji} - \sum_{k=1}^{i-1} L_{jk} L_{ik} \right)
$$</p>
</li>
</ul>
</li>
<li>
<p><strong>Result</strong>:</p>
<ul>
<li>$ \mathbf{L} $ is lower triangular.</li>
<li>$ \mathbf{L} \mathbf{L}^\top = \mathbf{A} $.</li>
</ul>
</li>
</ol>
<h4 id="93-significance-in-gptq"><strong>9.3. Significance in GPTQ</strong><a hidden class="anchor" aria-hidden="true" href="#93-significance-in-gptq">#</a></h4>
<ul>
<li>
<p><strong>Numerical Stability</strong>: Cholesky decomposition is numerically stable for positive-definite matrices.</p>
</li>
<li>
<p><strong>Efficient Solves</strong>: Allows solving linear systems $ \mathbf{A}\mathbf{x} = \mathbf{b} $ by:</p>
<ol>
<li>Forward substitution to solve $ \mathbf{L}\mathbf{y} = \mathbf{b} $.</li>
<li>Backward substitution to solve $ \mathbf{L}^\top \mathbf{x} = \mathbf{y} $.</li>
</ol>
</li>
<li>
<p><strong>Avoids Explicit Inversion</strong>: Inverting $ \mathbf{H} $ directly can be numerically unstable and computationally expensive.</p>
</li>
</ul>
<hr>
<h3 id="10-conclusion"><strong>10. Conclusion</strong><a hidden class="anchor" aria-hidden="true" href="#10-conclusion">#</a></h3>
<p>GPTQ is a powerful algorithm for quantizing large neural networks efficiently while maintaining high accuracy. By leveraging insights about quantization order, batching updates, and utilizing Cholesky decomposition, GPTQ addresses the computational and numerical challenges posed by large-scale models.</p>
<p><strong>Key Takeaways</strong>:</p>
<ul>
<li>
<p><strong>Hessian Matrix</strong>: Central to understanding how quantization errors propagate and how to adjust weights to minimize the overall error.</p>
</li>
<li>
<p><strong>Cholesky Decomposition</strong>: A numerically stable method to work with the Hessian inverse without explicit inversion, crucial for large models.</p>
</li>
<li>
<p><strong>Algorithm Efficiency</strong>: GPTQ&rsquo;s design reduces computational complexity, making it practical for models with billions of parameters.</p>
</li>
</ul>
<p>By understanding the mathematical foundations and practical implementations, we can appreciate the advancements GPTQ brings to the field of neural network quantization.</p>
<hr>
<p><strong>References</strong>:</p>
<ul>
<li>Frantar, E., &amp; Alistarh, D. (2022). Optimal Brain Quantization. <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>.</li>
<li>Nagel, M., Van Baalen, M., Blankevoort, T., &amp; Welling, M. (2020). Up or Down? Adaptive Rounding for Post-Training Quantization. <em>Proceedings of the International Conference on Machine Learning (ICML)</em>.</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer><script src="https://utteranc.es/client.js"
        repo="Shahid-Mo/Shahid-Mo.github.io"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">TensorTunes</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
